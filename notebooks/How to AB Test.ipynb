{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as scs\n",
    "from scipy.special import comb\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "import how_to_ab_test.sample_data as sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to AB Test\n",
    "\n",
    "This lab explores how one goes about AB testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Exact Test\n",
    "\n",
    "\n",
    "The Fisher exact test looks at the probability of this or more extreme a skew of success rates in a randomly drawn 2x2 contingency table conditioned on having the same marginals.\n",
    "\n",
    "Let\n",
    "<ul> \n",
    "    <li style=\"list-style-type: none;\">$N$ &nbsp;&nbsp; be the total number of draws;</li>\n",
    "    <li style=\"list-style-type: none;\">$n$ &nbsp;&nbsp; the number of draws in Group 0;</li>\n",
    "    <li style=\"list-style-type: none;\">$K$ &nbsp;&nbsp; the total number of successes;</li>\n",
    "</ul>\n",
    "\n",
    "Then, conditioning on the marginals leaves a single degree of freedom. This can, WLOG, be taken to be\n",
    "<ul>\n",
    "    <li style=\"list-style-type: none;\">$k$ &nbsp;&nbsp; the number of successes in Group 0;</li>\n",
    "</ul>\n",
    "\n",
    "Then, more extreme cases are $k > k_0$. (With the corresponding other $k < K-k_0$ for the two-sided test.)\n",
    "\n",
    "For the probability of this table being drawn ($k = k$) given the marginals, consider the analogy to drawing without replacement $k$ balls of type 1 and $n-k$ of type 2 from an urn with $K$ of type 1 and $N-K$ of type 2.\n",
    "\n",
    "To calculate this, we want the number of ways to draw the first row with the given split ($k$ out of $K$ from type 1 and $n-k$ from $N-K$) out of the possible ways to draw the first row ($n$ from a total $N$). (Note - having picked the first row, that fixes the whole table.)\n",
    "\n",
    "So we get the hypergeometric distribution:\n",
    "$$\n",
    "P(t_{0,0} = k) = \\frac{{K \\choose k}{N-K \\choose n-k}}{{N \\choose n}}\n",
    "$$\n",
    "\n",
    "For the p-value of the Fisher exact test, we then just sum over values of $k$ that are as or more extreme than the observed one.\n",
    "\n",
    "Implemented in `scipy.stats.fisher_exact`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_exact(table):\n",
    "    N = table.sum().sum()\n",
    "    n = table.sum(axis=1)[0]\n",
    "    K = table.sum(axis=0)[0]\n",
    "    k = table.iloc[0, 0]\n",
    "\n",
    "    num = 0\n",
    "    for ki in range(k, K+1):\n",
    "        num += comb(K, ki, exact=True) * comb(N-K, n-ki, exact=True)\n",
    "\n",
    "    return num / comb(N, n, exact=True)\n",
    "\n",
    "\n",
    "for table in sample_data.random_contingency_tables_2x2(10, is_equal_p=True):\n",
    "    odds_ratio, pvalue = scs.fisher_exact(table, alternative='greater')\n",
    "    pvalue_ = fisher_exact(table)\n",
    "    # print((pvalue, pvalue_))\n",
    "    assert abs(pvalue-pvalue_)<1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow Up: It looks very Bayes-like. Is there any interpretation along those lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Sample Z Test\n",
    "\n",
    "The z test is a large-sample approximation that the proportions in two groups are equal.\n",
    "\n",
    "It uses the fact that, by the CLT (and in practice converging very quickly - see below), the natural estimator for the group proportion is roughly normal:\n",
    "\n",
    "$$\n",
    "\\hat{p} := \\frac{X}{n} \\sim \\mathcal{N}\\Big(p, \\frac{p(1-p)}{n}\\Big)\n",
    "$$\n",
    "\n",
    "where $ X \\sim Binom(p, n)$.\n",
    "\n",
    "Note - It is a normal distribution, not a t. I haven't found a reference for this. Beyond that we are talking about large-sample (and so the t-test should be approximately normal anyways), I suspect that we have a normal distribution because the binomial is a single-parameter distribution so the extra degree of freedom for the SD doesn't exist in this case.\n",
    "\n",
    "To test the null hypothesis that the two groups come from the same distribution, we consider:\n",
    "\n",
    "$$\n",
    "z := \\hat{p_1} - \\hat{p_2} \\sim \\mathcal{N}\\big(0, \\hat{s}^2 \\big)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{s}^2 &= Var(\\hat{p}) \\\\\n",
    "    &= Var(\\hat{p_1}) + Var(\\hat{p_2}) \\\\\n",
    "    &= \\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1} + \\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "called the Satterthwaite approximation or we can pool, under the null hypothesis, the groups when estimating the SD, giving the pooled approximation\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{s}^2 &= Var(\\hat{p}) \\\\\n",
    "    &= Var(\\hat{p_1}) + Var(\\hat{p_2}) \\\\\n",
    "    &= \\frac{\\hat{p}(1-\\hat{p})}{n_1} + \\frac{\\hat{p}(1-\\hat{p})}{n_2} \\\\\n",
    "    &= \\hat{p}(1-\\hat{p}) \\Big( \\frac{1}{n_1} + \\frac{1}{n_2} \\Big)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\hat{p} = \\frac{n_1 p_1 + n_2 p_2}{n_1 + n_2} = \\frac{x_1 + x_2}{n_1 + n_2}\n",
    "$$\n",
    "\n",
    "The usual one-sided or two-sided tests are then as usual. \n",
    "\n",
    "Implemented in `statsmodels.stats.proportion.proportions_ztest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_ztest_(table, *, pooled_approx=False):\n",
    "    assert table.shape == (2, 2)\n",
    "\n",
    "    s1, s2 = table.iloc[:, 0]\n",
    "    n1, n2 = table.sum(axis=1)\n",
    "\n",
    "    p1, p2 = s1 / n1, s2 / n2\n",
    "\n",
    "    if pooled_approx:\n",
    "        p = (s1 + s2) / (n1 + n2)\n",
    "        v = p * (1 - p) * (1 / n1 + 1 / n2)\n",
    "    else:\n",
    "        v = p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2\n",
    "\n",
    "    if not v > 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    z_stat = (p1 - p2) / np.sqrt(v)\n",
    "\n",
    "    return z_stat, scs.norm.sf(np.abs(z_stat)) * 2\n",
    "\n",
    "\n",
    "for table in sample_data.random_contingency_tables_2x2(10, is_equal_p=True):\n",
    "    z_stat, pvalue = proportions_ztest(\n",
    "        table.Success, \n",
    "        table.Success+table.Fail, \n",
    "        alternative='two-sided',\n",
    "        prop_var=False\n",
    "    )\n",
    "    z_stat_, pvalue_ = proportions_ztest_(table, pooled_approx=True) \n",
    "    # print((pvalue, pvalue_))\n",
    "    assert (np.isnan(pvalue) and np.isnan(pvalue_)) or abs(pvalue-pvalue_)<1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test\n",
    "\n",
    "This is a large-sample approximation that two multinominial distribution match. Note that, unlike the Fisher and Z tests, it is limited to 2-sided tests but applies for any number of categories and groups.\n",
    "\n",
    "Given a multinomial sample \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    X &\\sim Multinomial_k(n, \\pi) \\\\\n",
    "    P(X=x) &= \\frac{n!}{x_1!...x_k!} \\pi_1^{x_1} ... \\pi_k^{x_k}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "it is shown that under $ H_0: \\pi = \\pi_0 $ we have\n",
    "\n",
    "$$\n",
    "X^2 = \\sum_{i=1}^k \\frac{(X_i - E_i)^2}{E_i} \\sim \\chi^2(k-1)\n",
    "$$\n",
    "\n",
    "where $ E_i = X_i * \\pi_i $.\n",
    "\n",
    "Extending to $g$ groups, we have\n",
    "\n",
    "$$\n",
    "X^2 = \\sum_{cells} \\frac{(X_i - E_i)^2}{E_i} = \\sum_{i=1}^{k} \\sum_{j=1}^g \\frac{(X_i^{(g)}-E_i)^2}{E_i} \\sim \\chi^2\\big((k-1)(g-1)\\big)\n",
    "$$\n",
    "\n",
    "where $E_i$ is estimated by the category totals $ E_i = \\sum_{j=1}^g X_i^{(g)}$\n",
    "\n",
    "Note: Cressie & Read extended this by remarking that this and a few other tests were related as special cases of a continuous family of the \"power divergence\" statistics:\n",
    "\n",
    "$$\n",
    "2n I^\\lambda = \\frac{2}{\\lambda (\\lambda + 1)} \\sum_{i=1}^k X_i\\Bigg( \\Big(\\frac{X_i}{E_i}\\Big)^\\lambda - 1 \\Bigg)\n",
    "$$\n",
    "\n",
    "Implemented in `scipy.stats.chi2_contingency`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_contingency(table):\n",
    "    by_category = table.values.sum(axis=0, keepdims=True)\n",
    "    pi = by_category/by_category.sum()\n",
    "    by_group = table.values.sum(axis=1, keepdims=True)\n",
    "\n",
    "    E = by_group*pi\n",
    "    \n",
    "    X2 = (np.square(table.values-E)/E).sum()\n",
    "    \n",
    "    dof = (table.shape[0]-1)*(table.shape[1]-1)\n",
    "    \n",
    "    return X2, 1.0 - scs.chi2.cdf(X2, dof), dof, E\n",
    "\n",
    "\n",
    "n = 10\n",
    "n_valid = 0\n",
    "for table in sample_data.random_contingency_tables_2x2(n, is_equal_p=True):\n",
    "    if not (table.sum(axis=0) == 0).any():\n",
    "        # chi2_contingency invalid if any category has 0 observed\n",
    "        n_valid += 1\n",
    "        chi2, pvalue, dof, expected = scs.chi2_contingency(table.values, correction=False)\n",
    "        chi2_, pvalue_, dof_, expected_ = chi2_contingency(table)\n",
    "        # print((pvalue, pvalue_))\n",
    "        assert abs(pvalue-pvalue_)<1e-8\n",
    "# print((n_valid, n))       \n",
    "assert n_valid > n/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "### Tests\n",
    "\n",
    "https://www.itl.nist.gov/div898/handbook/prc/section3/prc33.htm\n",
    "\n",
    "https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Two_Proportions.pdf\n",
    "\n",
    "https://www.jstor.org/stable/2983604\n",
    "\n",
    "https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f\n",
    "\n",
    "https://www.jstor.org/stable/2345686\n",
    "\n",
    "### Methodology\n",
    "\n",
    "http://blog.analytics-toolkit.com/2017/statistical-significance-ab-testing-complete-guide/\n",
    "\n",
    "https://www.analytics-toolkit.com/pdf/Efficient_AB_Testing_in_Conversion_Rate_Optimization_-_The_AGILE_Statistical_Method_2017.pdf\n",
    "\n",
    "https://www.evanmiller.org/how-not-to-run-an-ab-test.html\n",
    "\n",
    "https://www.chrisstucchio.com/blog/2015/dont_use_bandits.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
